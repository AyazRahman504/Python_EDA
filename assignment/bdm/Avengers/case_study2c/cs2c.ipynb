{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using AutoViz"
      ],
      "metadata": {
        "id": "lYAko67ZfD3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting Automated EDA Tools\n",
        "\n",
        "In this case study, we explored three Automated EDA Tools to understand their functionality and performance on a Malaysian dataset. The tools selected are: SweetViz,DataPrep and AutoViz.\n",
        "\n",
        "These tools were selected for their compatibility with Google Colab.\n"
      ],
      "metadata": {
        "id": "ms8kHbzLjbYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Malaysian Dataset\n",
        "\n",
        "The dataset used for this case study is as described in Case Study 1. Here is a brief overview of the dataset:\n",
        "\n",
        "We obtained a dataset from Kaggle containing user reviews of different resaurants around Malaysia from the website Trip Advisor. Our goal is to analyse this data to find Malaysian restuarant performance trends over time based on the user reviews, answering a number of important questions that are important to restaurants along the way. This is one of a two part assignment where we shall manually do Exploratory Data Analysis and generate conclusions with the other part requiring us to use some tools to get to obtain the same.\n",
        "\n"
      ],
      "metadata": {
        "id": "1HAJV_PqkX3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the Dataset\n",
        "In order to work with the dataset we are using, we have provided two options:\n",
        "\n",
        "**Alternative 1:** Kaggle Download Using the link provided  <a href=\"https://www.kaggle.com/datasets/choonkhonng/malaysia-restaurant-review-datasets\" target=\"_blank\" >here</a> click on it to open it in a new tab. Once you open it, it will take you to the Kaggle dataset dashboard. On the top right corner, there is an option to download the dataset (75MB). Download it and it will be locally available on your PC.\n",
        "\n",
        "**Alternative 2:** Github Link ,We have created a link on Github for our raw dataset <a href=\"https://raw.githubusercontent.com/BakungaBronson/Trip-Advisor-Dataset/main/TripAdvisor_data_cleaned.csv\" target=\"_blank\" >here</a>, which was downloaded from Kaggle. This makes it easier for everyone on the team to access it and use it for future reference. Click on the link and open it in a new tab. When the page is done loading, just press Ctrl + S (or Command + S for Mac users) to save the file."
      ],
      "metadata": {
        "id": "CL-tyNeJm--E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "\n",
        "The data obtained was already cleaned and tranformed accordingly, we can therefore continue to the next step.\n"
      ],
      "metadata": {
        "id": "Zm5pOx8gkzRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoviz Installation"
      ],
      "metadata": {
        "id": "UzaamWOJnSSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install AutoViz\n",
        "!pip install autoviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io56v0_anWgy",
        "outputId": "c1585da2-a406-47b1-9bed-2129e54bfcbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autoviz in /usr/local/lib/python3.10/dist-packages (0.1.732)\n",
            "Requirement already satisfied: bokeh~=2.4.2 in /usr/local/lib/python3.10/dist-packages (from autoviz) (2.4.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from autoviz) (2.8.0)\n",
            "Requirement already satisfied: fsspec>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from autoviz) (2023.6.0)\n",
            "Requirement already satisfied: holoviews~=1.14.9 in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.14.9)\n",
            "Requirement already satisfied: hvplot~=0.7.3 in /usr/local/lib/python3.10/dist-packages (from autoviz) (0.7.3)\n",
            "Requirement already satisfied: matplotlib>=3.3.3 in /usr/local/lib/python3.10/dist-packages (from autoviz) (3.7.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from autoviz) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.5.3)\n",
            "Requirement already satisfied: pandas-dq==1.28 in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.28)\n",
            "Requirement already satisfied: panel>=0.12.6 in /usr/local/lib/python3.10/dist-packages (from autoviz) (0.14.4)\n",
            "Requirement already satisfied: pyamg in /usr/local/lib/python3.10/dist-packages (from autoviz) (5.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from autoviz) (0.12.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from autoviz) (0.14.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from autoviz) (0.17.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from autoviz) (4.5.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.9.2)\n",
            "Requirement already satisfied: xgboost>=0.82 in /usr/local/lib/python3.10/dist-packages (from autoviz) (2.0.1)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from autoviz) (2.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh~=2.4.2->autoviz) (3.1.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh~=2.4.2->autoviz) (23.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh~=2.4.2->autoviz) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh~=2.4.2->autoviz) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh~=2.4.2->autoviz) (6.3.2)\n",
            "Requirement already satisfied: param<2.0,>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from holoviews~=1.14.9->autoviz) (1.13.0)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from holoviews~=1.14.9->autoviz) (3.0.0)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from holoviews~=1.14.9->autoviz) (3.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->autoviz) (2023.3.post1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (3.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (4.66.1)\n",
            "Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (6.1.0)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->autoviz) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->autoviz) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->autoviz) (3.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->autoviz) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->autoviz) (2023.6.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->autoviz) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh~=2.4.2->autoviz) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->autoviz) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=0.12.6->autoviz) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.12.6->autoviz) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.12.6->autoviz) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.12.6->autoviz) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.12.6->autoviz) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialising the libraraies needed"
      ],
      "metadata": {
        "id": "Sx28Dtg1lNdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import AutoViz and pandas\n",
        "from autoviz.AutoViz_Class import AutoViz_Class\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cnDNsyisbfaM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the Dataset"
      ],
      "metadata": {
        "id": "SOt0m045lHJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "df = df = pd.read_csv('https://raw.githubusercontent.com/BakungaBronson/Trip-Advisor-Dataset/main/TripAdvisor_data_cleaned.csv')  # Replace with your dataset path\n"
      ],
      "metadata": {
        "id": "HeGCRdx-nidR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report generation\n",
        "Autoviz comes with a class that can perform Exploratory Data Analysis and output the result to the cell for us. Run the commands below to generate and display the report for our dataset."
      ],
      "metadata": {
        "id": "NwvnXd1YlWRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the AutoViz class\n",
        "AV = AutoViz_Class()\n",
        "\n",
        "# Visualize your data\n",
        "autoviz_report = AV.AutoViz(\n",
        "    filename='', # No filename since we are using a dataframe\n",
        "    sep=',', # Separator in the data, e.g., CSV ',' or tab '\\t'\n",
        "    dfte=df, # The dataframe\n",
        "    depVar='', # Dependent variable, leave empty if no specific target variable\n",
        "    chart_format='svg' # 'svg' or 'png' to specify plot formats\n",
        ")\n",
        "\n",
        "# AutoViz will automatically generate a series of visualizations based on your dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XV18y8PznnmC",
        "outputId": "1f8bede1-a003-4280-a773-e8d186756635"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of your Data Set loaded: (139764, 7)\n",
            "#######################################################################################\n",
            "######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
            "#######################################################################################\n",
            "Classifying variables in data set...\n",
            "    7 Predictors classified...\n",
            "        No variables removed since no ID or low-information variables found in data set\n",
            "To fix data quality issues automatically, import FixDQ from autoviz...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7a7c26b23a90>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_3ff63_row0_col0, #T_3ff63_row0_col2, #T_3ff63_row0_col5, #T_3ff63_row1_col0, #T_3ff63_row1_col2, #T_3ff63_row1_col5, #T_3ff63_row2_col0, #T_3ff63_row2_col2, #T_3ff63_row2_col5, #T_3ff63_row3_col0, #T_3ff63_row3_col2, #T_3ff63_row3_col5, #T_3ff63_row4_col0, #T_3ff63_row4_col2, #T_3ff63_row4_col5, #T_3ff63_row5_col0, #T_3ff63_row5_col2, #T_3ff63_row5_col5, #T_3ff63_row6_col0, #T_3ff63_row6_col2, #T_3ff63_row6_col5 {\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "#T_3ff63_row0_col1, #T_3ff63_row0_col3, #T_3ff63_row0_col4, #T_3ff63_row1_col1, #T_3ff63_row1_col3, #T_3ff63_row1_col4, #T_3ff63_row2_col1, #T_3ff63_row2_col3, #T_3ff63_row2_col4, #T_3ff63_row3_col1, #T_3ff63_row3_col3, #T_3ff63_row3_col4, #T_3ff63_row4_col1, #T_3ff63_row4_col3, #T_3ff63_row4_col4, #T_3ff63_row5_col1, #T_3ff63_row5_col3, #T_3ff63_row5_col4, #T_3ff63_row6_col1, #T_3ff63_row6_col3, #T_3ff63_row6_col4 {\n",
              "  background-color: #fff5f0;\n",
              "  color: #000000;\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_3ff63\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_3ff63_level0_col0\" class=\"col_heading level0 col0\" >Data Type</th>\n",
              "      <th id=\"T_3ff63_level0_col1\" class=\"col_heading level0 col1\" >Missing Values%</th>\n",
              "      <th id=\"T_3ff63_level0_col2\" class=\"col_heading level0 col2\" >Unique Values%</th>\n",
              "      <th id=\"T_3ff63_level0_col3\" class=\"col_heading level0 col3\" >Minimum Value</th>\n",
              "      <th id=\"T_3ff63_level0_col4\" class=\"col_heading level0 col4\" >Maximum Value</th>\n",
              "      <th id=\"T_3ff63_level0_col5\" class=\"col_heading level0 col5\" >DQ Issue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_3ff63_level0_row0\" class=\"row_heading level0 row0\" >Author</th>\n",
              "      <td id=\"T_3ff63_row0_col0\" class=\"data row0 col0\" >object</td>\n",
              "      <td id=\"T_3ff63_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
              "      <td id=\"T_3ff63_row0_col2\" class=\"data row0 col2\" >67</td>\n",
              "      <td id=\"T_3ff63_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
              "      <td id=\"T_3ff63_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
              "      <td id=\"T_3ff63_row0_col5\" class=\"data row0 col5\" >94602 rare categories: Too many to list. Group them into a single category or drop the categories., high cardinality with 94602 unique values: Use hash encoding or embedding to reduce dimension.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3ff63_level0_row1\" class=\"row_heading level0 row1\" >Title</th>\n",
              "      <td id=\"T_3ff63_row1_col0\" class=\"data row1 col0\" >object</td>\n",
              "      <td id=\"T_3ff63_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
              "      <td id=\"T_3ff63_row1_col2\" class=\"data row1 col2\" >77</td>\n",
              "      <td id=\"T_3ff63_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
              "      <td id=\"T_3ff63_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
              "      <td id=\"T_3ff63_row1_col5\" class=\"data row1 col5\" >108925 rare categories: Too many to list. Group them into a single category or drop the categories., high cardinality with 108925 unique values: Use hash encoding or embedding to reduce dimension.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3ff63_level0_row2\" class=\"row_heading level0 row2\" >Review</th>\n",
              "      <td id=\"T_3ff63_row2_col0\" class=\"data row2 col0\" >object</td>\n",
              "      <td id=\"T_3ff63_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
              "      <td id=\"T_3ff63_row2_col2\" class=\"data row2 col2\" >99</td>\n",
              "      <td id=\"T_3ff63_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
              "      <td id=\"T_3ff63_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
              "      <td id=\"T_3ff63_row2_col5\" class=\"data row2 col5\" >138481 rare categories: Too many to list. Group them into a single category or drop the categories., high cardinality with 138481 unique values: Use hash encoding or embedding to reduce dimension.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3ff63_level0_row3\" class=\"row_heading level0 row3\" >Rating</th>\n",
              "      <td id=\"T_3ff63_row3_col0\" class=\"data row3 col0\" >float64</td>\n",
              "      <td id=\"T_3ff63_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
              "      <td id=\"T_3ff63_row3_col2\" class=\"data row3 col2\" >NA</td>\n",
              "      <td id=\"T_3ff63_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
              "      <td id=\"T_3ff63_row3_col4\" class=\"data row3 col4\" >5.000000</td>\n",
              "      <td id=\"T_3ff63_row3_col5\" class=\"data row3 col5\" >has 10537 outliers greater than upper bound (6.50) or lower than lower bound(2.50). Cap them or remove them.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3ff63_level0_row4\" class=\"row_heading level0 row4\" >Dates</th>\n",
              "      <td id=\"T_3ff63_row4_col0\" class=\"data row4 col0\" >object</td>\n",
              "      <td id=\"T_3ff63_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
              "      <td id=\"T_3ff63_row4_col2\" class=\"data row4 col2\" >3</td>\n",
              "      <td id=\"T_3ff63_row4_col3\" class=\"data row4 col3\" >nan</td>\n",
              "      <td id=\"T_3ff63_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
              "      <td id=\"T_3ff63_row4_col5\" class=\"data row4 col5\" >4390 rare categories: Too many to list. Group them into a single category or drop the categories., high cardinality with 4390 unique values: Use hash encoding or embedding to reduce dimension.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3ff63_level0_row5\" class=\"row_heading level0 row5\" >Restaurant</th>\n",
              "      <td id=\"T_3ff63_row5_col0\" class=\"data row5 col0\" >object</td>\n",
              "      <td id=\"T_3ff63_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
              "      <td id=\"T_3ff63_row5_col2\" class=\"data row5 col2\" >1</td>\n",
              "      <td id=\"T_3ff63_row5_col3\" class=\"data row5 col3\" >nan</td>\n",
              "      <td id=\"T_3ff63_row5_col4\" class=\"data row5 col4\" >nan</td>\n",
              "      <td id=\"T_3ff63_row5_col5\" class=\"data row5 col5\" >2541 rare categories: Too many to list. Group them into a single category or drop the categories., high cardinality with 2544 unique values: Use hash encoding or embedding to reduce dimension.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3ff63_level0_row6\" class=\"row_heading level0 row6\" >Location</th>\n",
              "      <td id=\"T_3ff63_row6_col0\" class=\"data row6 col0\" >object</td>\n",
              "      <td id=\"T_3ff63_row6_col1\" class=\"data row6 col1\" >0.000000</td>\n",
              "      <td id=\"T_3ff63_row6_col2\" class=\"data row6 col2\" >0</td>\n",
              "      <td id=\"T_3ff63_row6_col3\" class=\"data row6 col3\" >nan</td>\n",
              "      <td id=\"T_3ff63_row6_col4\" class=\"data row6 col4\" >nan</td>\n",
              "      <td id=\"T_3ff63_row6_col5\" class=\"data row6 col5\" >1 rare categories: ['Petaling Jaya']. Group them into a single category or drop the categories.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Plots done\n",
            "Time to run AutoViz = 378 seconds \n",
            "\n",
            " ###################### AUTO VISUALIZATION Completed ########################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pros and Cons Analysis\n",
        "\n",
        "### Autoviz\n",
        "\n",
        "- **Pros**:\n",
        "  - Easy to install and use.\n",
        "  - Simple visualizations with summaries at the top of the report.\n",
        "- **Cons**:\n",
        "  - Too slow to output results taking over 7 mins in our case.\n",
        "\n",
        "Based on the analysis, the performance of each tool on the Malaysian dataset is discussed.\n"
      ],
      "metadata": {
        "id": "mZXsv9KQl2pH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "This case study provided insights into the use of Automated EDA Tools on a Malaysian dataset. Key findings include:\n",
        "\n",
        "- The tool is great because of it's ease of use however it is too slow compared to the other tools we have used.\n"
      ],
      "metadata": {
        "id": "Y7o_mONhmlbr"
      }
    }
  ]
}